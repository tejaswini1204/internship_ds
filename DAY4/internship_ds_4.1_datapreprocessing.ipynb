{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name   Age    Salary  Dept_HR  Dept_IT  Dept_Marketing\n",
      "0   John  0.30  0.333333    False     True           False\n",
      "1   Jane  1.00  0.250000     True    False           False\n",
      "2    Doe  0.45  0.000000    False    False            True\n",
      "3  Alice  0.50  1.000000    False     True           False\n",
      "4    Bob  0.00  0.166667     True    False           False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThe provided code snippet performs basic data preprocessing on a sample dataset using pandas and scikit-learn:\\n\\n1. **Handling Missing Data**:\\n   - Fills missing values in 'Age' with the mean and in 'Salary' with the median.\\n\\n2. **Converting Data Types**:\\n   - Converts 'Age' and 'Salary' columns to numeric types.\\n\\n3. **Normalization**:\\n   - Normalizes 'Age' and 'Salary' columns using Min-Max scaling to range [0, 1].\\n\\n4. **Encoding Categorical Data**:\\n   - Converts categorical variable 'Department' into dummy variables.\\n\\nThis process ensures the dataset is ready for further analysis or modeling by addressing missing values, standardizing data types, scaling numeric features, and encoding categorical variables.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Name': ['John', 'Jane', 'Doe', 'Alice', 'Bob'],\n",
    "    'Age': [28, 35, None, 30, 25],\n",
    "    'Salary': [50000, None, 40000, 70000, 45000],\n",
    "    'Department': ['IT', 'HR', 'Marketing', 'IT', 'HR']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fill missing Age with mean age\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "\n",
    "# Fill missing Salary with median salary\n",
    "df['Salary'].fillna(df['Salary'].median(), inplace=True)\n",
    "\n",
    "# Convert Age and Salary to numeric types if they are not already\n",
    "df['Age'] = pd.to_numeric(df['Age'])\n",
    "df['Salary'] = pd.to_numeric(df['Salary'])\n",
    "\n",
    "# Normalize Age and Salary\n",
    "scaler = MinMaxScaler()\n",
    "df[['Age', 'Salary']] = scaler.fit_transform(df[['Age', 'Salary']])\n",
    "\n",
    "# Convert the Department column into dummy variables\n",
    "df = pd.get_dummies(df, columns=['Department'], prefix='Dept')\n",
    "\n",
    "print(df)\n",
    "'''\n",
    "The provided code snippet performs basic data preprocessing on a sample dataset using pandas and scikit-learn:\n",
    "\n",
    "1. **Handling Missing Data**:\n",
    "   - Fills missing values in 'Age' with the mean and in 'Salary' with the median.\n",
    "\n",
    "2. **Converting Data Types**:\n",
    "   - Converts 'Age' and 'Salary' columns to numeric types.\n",
    "\n",
    "3. **Normalization**:\n",
    "   - Normalizes 'Age' and 'Salary' columns using Min-Max scaling to range [0, 1].\n",
    "\n",
    "4. **Encoding Categorical Data**:\n",
    "   - Converts categorical variable 'Department' into dummy variables.\n",
    "\n",
    "This process ensures the dataset is ready for further analysis or modeling by addressing missing values, standardizing data types, scaling numeric features, and encoding categorical variables.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarisation\n",
    "\n",
    "In the below example, we used threshold value = 0.5 and that is why, all the values\n",
    "above 0.5 would be converted to 1, and all the values below 0.5 would be converted to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Binarized data:\n",
      " [[1. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe provided code snippet demonstrates how to perform binarization on a numerical dataset using scikit-learn\\'s `preprocessing.Binarizer` class. Here’s a detailed explanation of each part:\\n\\n1. **Importing Libraries**:\\n   - `import numpy as np`: Imports the NumPy library under the alias `np`, which provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.\\n   - `from sklearn import preprocessing`: Imports the `preprocessing` module from scikit-learn, which includes utilities for data preprocessing and feature engineering.\\n\\n2. **Defining Input Data**:\\n   - `Input_data = np.array([[2.1, -1.9, 5.5],\\n     [-1.5, 2.4, 3.5],\\n     [0.5, -7.9, 5.6],\\n     [5.9, 2.3, -5.8]])`: Defines a 2D NumPy array (`Input_data`) containing numerical values. Each row represents a sample (observation) and each column represents a feature.\\n\\n3. **Binarization**:\\n   - `preprocessing.Binarizer(threshold=0.5)`: Creates an instance of the `Binarizer` class from scikit-learn\\'s `preprocessing` module. The `threshold=0.5` parameter specifies the threshold value. Any value in `Input_data` greater than `0.5` will be transformed to `1`, and any value less than or equal to `0.5` will be transformed to `0`.\\n   - `.transform(Input_data)`: Applies the binarization transformation to `Input_data` using the specified threshold (`0.5`). This converts each numerical value in `Input_data` into a binary value (either `0` or `1`), based on whether it exceeds the threshold.\\n\\n4. **Printing Binarized Data**:\\n   - `print(\"\\nBinarized data:\\n\", data_binarized)`: Prints the binarized data (`data_binarized`). This output displays the transformed array where each element has been replaced by `1` or `0` based on whether it exceeds `0.5`.\\n\\n**Explanation of Binarization**:\\n   Binarization is a common preprocessing technique used to convert numeric data into a binary format. In this case:\\n   - Values greater than `0.5` are converted to `1`.\\n   - Values less than or equal to `0.5` are converted to `0`.\\n\\nThis transformation is useful in scenarios where only the presence or absence of a feature is relevant, rather than its specific numeric value. It\\'s often applied in machine learning tasks where algorithms expect binary inputs or when certain thresholds need to be established for decision-making processes.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Binarisation\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "Input_data = np.array([[2.1, -1.9, 5.5],\n",
    " [-1.5, 2.4, 3.5],\n",
    " [0.5, -7.9, 5.6],\n",
    " [5.9, 2.3, -5.8]])\n",
    "data_binarized = preprocessing.Binarizer(threshold=0.5).transform(Input_data)\n",
    "print(\"\\nBinarized data:\\n\", data_binarized)\n",
    "'''\n",
    "The provided code snippet demonstrates how to perform binarization on a numerical dataset using scikit-learn's `preprocessing.Binarizer` class. Here’s a detailed explanation of each part:\n",
    "\n",
    "1. **Importing Libraries**:\n",
    "   - `import numpy as np`: Imports the NumPy library under the alias `np`, which provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.\n",
    "   - `from sklearn import preprocessing`: Imports the `preprocessing` module from scikit-learn, which includes utilities for data preprocessing and feature engineering.\n",
    "\n",
    "2. **Defining Input Data**:\n",
    "   - `Input_data = np.array([[2.1, -1.9, 5.5],\n",
    "     [-1.5, 2.4, 3.5],\n",
    "     [0.5, -7.9, 5.6],\n",
    "     [5.9, 2.3, -5.8]])`: Defines a 2D NumPy array (`Input_data`) containing numerical values. Each row represents a sample (observation) and each column represents a feature.\n",
    "\n",
    "3. **Binarization**:\n",
    "   - `preprocessing.Binarizer(threshold=0.5)`: Creates an instance of the `Binarizer` class from scikit-learn's `preprocessing` module. The `threshold=0.5` parameter specifies the threshold value. Any value in `Input_data` greater than `0.5` will be transformed to `1`, and any value less than or equal to `0.5` will be transformed to `0`.\n",
    "   - `.transform(Input_data)`: Applies the binarization transformation to `Input_data` using the specified threshold (`0.5`). This converts each numerical value in `Input_data` into a binary value (either `0` or `1`), based on whether it exceeds the threshold.\n",
    "\n",
    "4. **Printing Binarized Data**:\n",
    "   - `print(\"\\nBinarized data:\\n\", data_binarized)`: Prints the binarized data (`data_binarized`). This output displays the transformed array where each element has been replaced by `1` or `0` based on whether it exceeds `0.5`.\n",
    "\n",
    "**Explanation of Binarization**:\n",
    "   Binarization is a common preprocessing technique used to convert numeric data into a binary format. In this case:\n",
    "   - Values greater than `0.5` are converted to `1`.\n",
    "   - Values less than or equal to `0.5` are converted to `0`.\n",
    "\n",
    "This transformation is useful in scenarios where only the presence or absence of a feature is relevant, rather than its specific numeric value. It's often applied in machine learning tasks where algorithms expect binary inputs or when certain thresholds need to be established for decision-making processes.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Removal\n",
    "This technique is used to eliminate the mean from feature vector so that every feature\n",
    "centered on zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean = [ 1.75  -1.275  2.2  ]\n",
      "Stddeviation =  [2.71431391 4.20022321 4.69414529]\n",
      "Mean_removed = [1.11022302e-16 0.00000000e+00 0.00000000e+00]\n",
      "Stddeviation_removed = [1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThe code snippet demonstrates mean removal (standardization) using scikit-learn's `preprocessing.scale` function:\\n\\n1. **Input Data and Statistics**:\\n   - Defines `input_data`, a 2D NumPy array with numerical values representing samples and features.\\n   - Prints the mean and standard deviation of each feature in `input_data`.\\n\\n2. **Mean Removal (Standardization)**:\\n   - Uses `preprocessing.scale(input_data)` to transform `input_data` such that each feature has a mean of `0` and standard deviation of `1`.\\n   - Prints the mean and standard deviation of each feature in the standardized data (`data_scaled`).\\n\\n**Explanation**:\\n   Mean removal (standardization) adjusts the data distribution to have a mean of `0` and standard deviation of `1`. This preprocessing step is essential for algorithms that assume normally distributed data or require consistent feature scaling. It improves model performance and facilitates comparison between different features in the dataset.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean Removal\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "input_data = np.array([[2.1, -1.9, 5.5],\n",
    "[-1.5, 2.4, 3.5],\n",
    " [0.5, -7.9, 5.6],\n",
    " [5.9, 2.3, -5.8]])\n",
    "#displaying the mean and the standard deviation of the input data\n",
    "print(\"Mean =\", input_data.mean(axis=0))\n",
    "print(\"Stddeviation = \", input_data.std(axis=0))\n",
    "#Removing the mean and the standard deviation of the input data\n",
    "data_scaled = preprocessing.scale(input_data)\n",
    "print(\"Mean_removed =\", data_scaled.mean(axis=0))\n",
    "print(\"Stddeviation_removed =\", data_scaled.std(axis=0))\n",
    "'''\n",
    "The code snippet demonstrates mean removal (standardization) using scikit-learn's `preprocessing.scale` function:\n",
    "\n",
    "1. **Input Data and Statistics**:\n",
    "   - Defines `input_data`, a 2D NumPy array with numerical values representing samples and features.\n",
    "   - Prints the mean and standard deviation of each feature in `input_data`.\n",
    "\n",
    "2. **Mean Removal (Standardization)**:\n",
    "   - Uses `preprocessing.scale(input_data)` to transform `input_data` such that each feature has a mean of `0` and standard deviation of `1`.\n",
    "   - Prints the mean and standard deviation of each feature in the standardized data (`data_scaled`).\n",
    "\n",
    "**Explanation**:\n",
    "   Mean removal (standardization) adjusts the data distribution to have a mean of `0` and standard deviation of `1`. This preprocessing step is essential for algorithms that assume normally distributed data or require consistent feature scaling. It improves model performance and facilitates comparison between different features in the dataset.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling\n",
    "We use this preprocessing technique for scaling the feature vectors. Scaling of feature\n",
    "vectors is important, because the features should not be synthetically large or small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Min max scaled data:\n",
      " [[0.48648649 0.58252427 0.99122807]\n",
      " [0.         1.         0.81578947]\n",
      " [0.27027027 0.         1.        ]\n",
      " [1.         0.99029126 0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThe code snippet demonstrates Min-Max scaling using scikit-learn's `preprocessing.MinMaxScaler`:\\n\\n1. **Input Data**:\\n   - Defines `input_data`, a 2D NumPy array with numerical values representing samples and features.\\n\\n2. **Min-Max Scaling**:\\n   - Initializes `data_scaler_minmax` with `MinMaxScaler(feature_range=(0,1))`, setting the range for scaled values to [0, 1].\\n   - Applies `fit_transform(input_data)` to compute and transform `input_data` into `data_scaled_minmax`, where each feature is scaled to the specified range.\\n\\n3. **Output**:\\n   - Prints `data_scaled_minmax`, displaying the transformed data with each feature scaled to [0, 1].\\n\\n**Explanation**:\\n   Min-Max scaling adjusts data such that each feature falls within a specified range (here, [0, 1]). This normalization technique is useful for algorithms sensitive to varying scales across features, ensuring uniformity and aiding in accurate model training and interpretation.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "input_data = np.array([[2.1, -1.9, 5.5],\n",
    "\n",
    " [-1.5, 2.4, 3.5],\n",
    " [0.5, -7.9, 5.6],\n",
    " [5.9, 2.3, -5.8]])\n",
    "data_scaler_minmax = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "data_scaled_minmax = data_scaler_minmax.fit_transform(input_data)\n",
    "print (\"\\nMin max scaled data:\\n\", data_scaled_minmax)\n",
    "'''\n",
    "The code snippet demonstrates Min-Max scaling using scikit-learn's `preprocessing.MinMaxScaler`:\n",
    "\n",
    "1. **Input Data**:\n",
    "   - Defines `input_data`, a 2D NumPy array with numerical values representing samples and features.\n",
    "\n",
    "2. **Min-Max Scaling**:\n",
    "   - Initializes `data_scaler_minmax` with `MinMaxScaler(feature_range=(0,1))`, setting the range for scaled values to [0, 1].\n",
    "   - Applies `fit_transform(input_data)` to compute and transform `input_data` into `data_scaled_minmax`, where each feature is scaled to the specified range.\n",
    "\n",
    "3. **Output**:\n",
    "   - Prints `data_scaled_minmax`, displaying the transformed data with each feature scaled to [0, 1].\n",
    "\n",
    "**Explanation**:\n",
    "   Min-Max scaling adjusts data such that each feature falls within a specified range (here, [0, 1]). This normalization technique is useful for algorithms sensitive to varying scales across features, ensuring uniformity and aiding in accurate model training and interpretation.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L1 normalized data:\n",
      " [[ 0.22105263 -0.2         0.57894737]\n",
      " [-0.2027027   0.32432432  0.47297297]\n",
      " [ 0.03571429 -0.56428571  0.4       ]\n",
      " [ 0.42142857  0.16428571 -0.41428571]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThe code snippet demonstrates L1 normalization using scikit-learn's `preprocessing.normalize` function:\\n\\n1. **Input Data**:\\n   - Defines `input_data`, a 2D NumPy array containing numerical values representing samples and features.\\n\\n2. **L1 Normalization**:\\n   - Applies `preprocessing.normalize(input_data, norm='l1')` to normalize each sample (row) in `input_data` using L1 normalization. L1 normalization calculates the norm by summing the absolute values of each feature for a sample and then scales each feature proportionally so that the sum of absolute values equals 1.\\n\\n3. **Output**:\\n   - Prints `data_normalized_l1`, displaying the normalized data where each row's values sum up to 1 (L1 norm).\\n\\n**Explanation**:\\n   L1 normalization, also known as least absolute deviations or Manhattan normalization, scales each sample individually such that the sum of absolute values of its features equals 1. This technique is useful when data needs to be transformed into a probability distribution or when the direction of the vector matters more than its magnitude. L1 normalization ensures that each sample is weighted equally based on the absolute contribution of its features.\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#L1 Normalistion\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "input_data = np.array([[2.1, -1.9, 5.5],\n",
    " [-1.5, 2.4, 3.5],\n",
    " [0.5, -7.9, 5.6],\n",
    " [5.9, 2.3, -5.8]])\n",
    "data_normalized_l1 = preprocessing.normalize(input_data, norm='l1')\n",
    "print(\"\\nL1 normalized data:\\n\", data_normalized_l1)\n",
    "'''\n",
    "The code snippet demonstrates L1 normalization using scikit-learn's `preprocessing.normalize` function:\n",
    "\n",
    "1. **Input Data**:\n",
    "   - Defines `input_data`, a 2D NumPy array containing numerical values representing samples and features.\n",
    "\n",
    "2. **L1 Normalization**:\n",
    "   - Applies `preprocessing.normalize(input_data, norm='l1')` to normalize each sample (row) in `input_data` using L1 normalization. L1 normalization calculates the norm by summing the absolute values of each feature for a sample and then scales each feature proportionally so that the sum of absolute values equals 1.\n",
    "\n",
    "3. **Output**:\n",
    "   - Prints `data_normalized_l1`, displaying the normalized data where each row's values sum up to 1 (L1 norm).\n",
    "\n",
    "**Explanation**:\n",
    "   L1 normalization, also known as least absolute deviations or Manhattan normalization, scales each sample individually such that the sum of absolute values of its features equals 1. This technique is useful when data needs to be transformed into a probability distribution or when the direction of the vector matters more than its magnitude. L1 normalization ensures that each sample is weighted equally based on the absolute contribution of its features.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L2 normalized data:\n",
      " [[ 0.33946114 -0.30713151  0.88906489]\n",
      " [-0.33325106  0.53320169  0.7775858 ]\n",
      " [ 0.05156558 -0.81473612  0.57753446]\n",
      " [ 0.68706914  0.26784051 -0.6754239 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThe provided code snippet demonstrates L2 normalization using scikit-learn's `preprocessing.normalize` function:\\n\\n1. **Input Data**:\\n   - Defines `input_data`, a 2D NumPy array containing numerical values representing samples and features.\\n\\n2. **L2 Normalization**:\\n   - Applies `preprocessing.normalize(input_data, norm='l2')` to normalize each sample (row) in `input_data` using L2 normalization. L2 normalization calculates the norm by summing the squares of each feature for a sample and then scales each feature proportionally so that the Euclidean norm (L2 norm) equals 1.\\n\\n3. **Output**:\\n   - Prints `data_normalized_l2`, displaying the normalized data where each row's Euclidean norm (L2 norm) equals 1.\\n\\n**Explanation**:\\n   L2 normalization, also known as Euclidean normalization, scales each sample individually such that the Euclidean norm (magnitude) of its feature vector equals 1. This technique is useful for ensuring that data lies on the unit hypersphere, making it invariant to the scale of individual samples. L2 normalization is commonly used in machine learning algorithms that rely on distances or similarity measures between samples.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#L2 Normalisation\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "input_data = np.array([[2.1, -1.9, 5.5],\n",
    " [-1.5, 2.4, 3.5],\n",
    " [0.5, -7.9, 5.6],\n",
    " [5.9, 2.3, -5.8]])\n",
    "data_normalized_l2 = preprocessing.normalize(input_data, norm='l2')\n",
    "print(\"\\nL2 normalized data:\\n\", data_normalized_l2)\n",
    "'''\n",
    "The provided code snippet demonstrates L2 normalization using scikit-learn's `preprocessing.normalize` function:\n",
    "\n",
    "1. **Input Data**:\n",
    "   - Defines `input_data`, a 2D NumPy array containing numerical values representing samples and features.\n",
    "\n",
    "2. **L2 Normalization**:\n",
    "   - Applies `preprocessing.normalize(input_data, norm='l2')` to normalize each sample (row) in `input_data` using L2 normalization. L2 normalization calculates the norm by summing the squares of each feature for a sample and then scales each feature proportionally so that the Euclidean norm (L2 norm) equals 1.\n",
    "\n",
    "3. **Output**:\n",
    "   - Prints `data_normalized_l2`, displaying the normalized data where each row's Euclidean norm (L2 norm) equals 1.\n",
    "\n",
    "**Explanation**:\n",
    "   L2 normalization, also known as Euclidean normalization, scales each sample individually such that the Euclidean norm (magnitude) of its feature vector equals 1. This technique is useful for ensuring that data lies on the unit hypersphere, making it invariant to the scale of individual samples. L2 normalization is commonly used in machine learning algorithms that rely on distances or similarity measures between samples.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 13 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   pclass     1309 non-null   float64 \n",
      " 1   name       1309 non-null   object  \n",
      " 2   sex        1309 non-null   category\n",
      " 3   age        1046 non-null   float64 \n",
      " 4   sibsp      1309 non-null   float64 \n",
      " 5   parch      1309 non-null   float64 \n",
      " 6   ticket     1309 non-null   object  \n",
      " 7   fare       1308 non-null   float64 \n",
      " 8   cabin      295 non-null    object  \n",
      " 9   embarked   1307 non-null   category\n",
      " 10  boat       486 non-null    object  \n",
      " 11  body       121 non-null    float64 \n",
      " 12  home.dest  745 non-null    object  \n",
      "dtypes: category(2), float64(6), object(5)\n",
      "memory usage: 115.4+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hetan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\datasets\\_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThe provided code snippet demonstrates fetching a dataset ('titanic') from OpenML using scikit-learn's `fetch_openml` function and storing it as a pandas DataFrame (`df`).\\n\\n**Explanation in Paragraph**:\\nThe code imports the necessary libraries, including pandas (`pd`) for data manipulation and scikit-learn's `fetch_openml` function to retrieve datasets from OpenML. It fetches the 'titanic' dataset with version 1 and loads it into a pandas DataFrame (`df`) using the `as_frame=True` parameter. The `info()` method called on `df` prints concise information about the DataFrame, including the number of non-null values in each column and the data types. This step ensures that the dataset is successfully loaded into memory and provides an overview of its structure and characteristics, facilitating further analysis or preprocessing tasks.\\n\\n**Explanation in Short**:\\nThe code fetches the 'titanic' dataset from OpenML using scikit-learn, stores it as a pandas DataFrame (`df`), and prints a summary of its information using `df.info()`. This confirms the dataset's loading and provides insights into its structure and attributes for subsequent data analysis or modeling tasks.\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stroing a dataset into dataframes\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml  #fetch openml functionality\n",
    "df=fetch_openml('titanic',version=1,as_frame=True)['data']\n",
    "df.info()\n",
    "'''\n",
    "The code fetches the 'titanic' dataset from OpenML using scikit-learn, loads it into a pandas DataFrame (`df`), and prints a summary with `df.info()`, confirming successful loading and providing an overview of the dataset's structure for further analysis.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe `df.isnull()` method checks every cell in the DataFrame `df` to see if it contains a missing value (NaN or None). It returns a DataFrame of the same shape as `df` where each cell is `True` if it is missing and `False` otherwise. This is useful for quickly identifying the presence of missing data in the dataset, which is essential for data cleaning and preprocessing tasks before analysis or modeling.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding missing values in datset\n",
    "df.isnull()\n",
    "'''\n",
    "The `df.isnull()` method checks every cell in the DataFrame `df` to see if it contains a missing value (NaN or None). It returns a DataFrame of the same shape as `df` where each cell is `True` if it is missing and `False` otherwise. This is useful for quickly identifying the presence of missing data in the dataset, which is essential for data cleaning and preprocessing tasks before analysis or modeling.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass          0\n",
       "name            0\n",
       "sex             0\n",
       "age           263\n",
       "sibsp           0\n",
       "parch           0\n",
       "ticket          0\n",
       "fare            1\n",
       "cabin        1014\n",
       "embarked        2\n",
       "boat          823\n",
       "body         1188\n",
       "home.dest     564\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summing the null values across every column\n",
    "'''\n",
    "`df.isnull().sum()` calculates and returns the total number of missing values (NaN or None) in each column of the DataFrame `df`. This provides a quick summary of missing data across all columns, aiding in prioritizing columns for data cleaning or imputation strategies during preprocessing.\n",
    "'''\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset before dropping body column: (5, 2)\n",
      "Size of the dataset after dropping body column: (5, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nYour code efficiently handles missing values by first calculating and visualizing the percentage of null entries in each column using Seaborn. It generates a bar plot to highlight the proportion of missing data, making it easy to identify problematic columns. Upon identifying that the 'body' column has the highest percentage of missing values, the code drops this column from the DataFrame to clean the dataset. The dataset's shape is printed before and after dropping the column to confirm the change, ensuring that the DataFrame's modification is successfully sustained. This concise approach aids in both visualizing and managing missing data effectively.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Sample DataFrame for demonstration\n",
    "data = {'age': [25, np.nan, 30, np.nan, 35], 'body': [np.nan, np.nan, 'slim', 'athletic', 'average']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Visualize missing values with seaborn\n",
    "sns.set()\n",
    "\n",
    "# Calculate the percentage of missing values\n",
    "miss_val_per = (df.isnull().sum() / len(df)) * 100\n",
    "miss_val_per = miss_val_per.reset_index()\n",
    "miss_val_per.columns = ['column', 'percentage']\n",
    "\n",
    "# Plot the missing values\n",
    "miss_val_per.plot(kind='bar', x='column', y='percentage', title='Missing values in percentage')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()\n",
    "\n",
    "# Print the size of the dataset before dropping the 'body' column\n",
    "print(f'Size of the dataset before dropping body column: {df.shape}')\n",
    "\n",
    "# Drop the 'body' column\n",
    "df.drop('body', axis=1, inplace=True)\n",
    "\n",
    "# Print the size of the dataset after dropping the 'body' column\n",
    "print(f'Size of the dataset after dropping body column: {df.shape}')\n",
    "'''\n",
    "Your code efficiently handles missing values by first calculating and visualizing the percentage of null entries in each column using Seaborn. It generates a bar plot to highlight the proportion of missing data, making it easy to identify problematic columns. Upon identifying that the 'body' column has the highest percentage of missing values, the code drops this column from the DataFrame to clean the dataset. The dataset's shape is printed before and after dropping the column to confirm the change, ensuring that the DataFrame's modification is successfully sustained. This concise approach aids in both visualizing and managing missing data effectively.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values before imputing: 2\n",
      "Number of null values after imputing: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nIn this code, missing values in the 'age' column are addressed using `SimpleImputer` from the `sklearn.impute` module. Initially, the code prints the number of missing values in the 'age' column. The `SimpleImputer` is then configured to replace missing values with the mean of the non-missing values in the column. The `fit_transform` method is applied to the 'age' column to perform the imputation, replacing any `NaN` values with the calculated mean. After imputation, the code prints the number of missing values again, demonstrating that all missing entries in the 'age' column have been successfully filled. This method ensures that the data is complete, which is crucial for subsequent analysis or modeling.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treating the missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame for demonstration\n",
    "data = {'age': [25, None, 30, None, 35]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check for null values before imputing\n",
    "print(f'Number of null values before imputing: {df[\"age\"].isnull().sum()}')\n",
    "\n",
    "# Creating and applying the SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df['age'] = imputer.fit_transform(df[['age']])\n",
    "\n",
    "# Check for null values after imputing\n",
    "print(f'Number of null values after imputing: {df[\"age\"].isnull().sum()}')\n",
    "'''\n",
    "In this code, missing values in the 'age' column are addressed using `SimpleImputer` from the `sklearn.impute` module. Initially, the code prints the number of missing values in the 'age' column. The `SimpleImputer` is then configured to replace missing values with the mean of the non-missing values in the column. The `fit_transform` method is applied to the 'age' column to perform the imputation, replacing any `NaN` values with the calculated mean. After imputation, the code prints the number of missing values again, demonstrating that all missing entries in the 'age' column have been successfully filled. This method ensures that the data is complete, which is crucial for subsequent analysis or modeling.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing Template\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Data.csv')\n",
    "X = dataset.iloc[:, :-1].values   #integer location based indexing\n",
    "y = dataset.iloc[:, -1].values    #selecting rows and columns by their integer position\n",
    "#This line selects all the columns except the last one\n",
    "#(which typically contain the features or predictors in the dataset) and stores them in X as a NumPy array.\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "'''\n",
    "The provided code template is designed for basic data preprocessing. It begins by importing essential libraries: NumPy for numerical operations, Matplotlib for visualization, and Pandas for data handling. The dataset is read from a CSV file, with features (all columns except the last) assigned to `X` and the target variable (the last column) assigned to `y`. The dataset is then split into training and testing sets using `train_test_split` from `sklearn.model_selection`, allocating 80% of the data for training and 20% for testing. This ensures that the data is prepared for model training and evaluation in a structured manner.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n",
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n",
      "[0 1 0 0 1 1 0 1 0 1]\n",
      "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]]\n",
      "[[0.0 1.0 0.0 30.0 54000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n",
      "[0 1 0 0 1 1 0 1]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing Tools\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Data.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "# Taking care of missing data\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
    "print(X)\n",
    "\n",
    "# Encoding categorical data\n",
    "# Encoding the Independent Variable\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "print(X)\n",
    "# Encoding the Dependent Variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(y)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "'''\n",
    "The provided code performs comprehensive data preprocessing. It starts by importing necessary libraries: NumPy, Matplotlib, and Pandas. The dataset is loaded from a CSV file into a DataFrame, with features stored in `X` and the target variable in `y`. Missing data in `X` is addressed using `SimpleImputer`, replacing missing values with the mean of the respective columns. \n",
    "\n",
    "Next, categorical data is encoded: independent variables are one-hot encoded using `ColumnTransformer` and `OneHotEncoder`, transforming categorical columns into numerical format, and the dependent variable is label encoded using `LabelEncoder`. The dataset is then split into training and testing sets using `train_test_split`, allocating 80% of the data for training and 20% for testing. This process ensures the dataset is cleaned, encoded, and split appropriately for further analysis or model training.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
